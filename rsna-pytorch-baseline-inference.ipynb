{"cells":[{"metadata":{},"cell_type":"markdown","source":"# RSNA: Pytorch Baseline-inference\n\n[Here](https://www.kaggle.com/maunish/rsna-super-cool-eda-and-pytorch-baseline-train) is notebook for training code.\n"},{"metadata":{},"cell_type":"markdown","source":"### Import Libraries ðŸ“˜"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"import random\nimport os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.functional as F\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import models\nfrom torch.utils.data import Dataset,DataLoader\nimport cv2\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nfrom sklearn.model_selection import KFold\n\nimport vtk\nfrom vtk.util import numpy_support\nfrom tqdm.auto import tqdm\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folder_path = \"../input/rsna-str-pulmonary-embolism-detection\"\ntrain_path = folder_path + \"/train/\"\ntest_path = folder_path + \"/test/\"\n    \n# train_data = pd.read_csv(folder_path + \"/train.csv\")\ntest_data  = pd.read_csv(folder_path + \"/test.csv\")\nsample = pd.read_csv(folder_path + \"/sample_submission.csv\")\n\ncols_ID = [\"StudyInstanceUID\",\"SeriesInstanceUID\",\"SOPInstanceUID\"]\ntest_data[\"ImagePath\"] = test_path+ test_data[cols_ID[0]]+\"/\"+test_data[cols_ID[1]]+\"/\"+test_data[cols_ID[2]]+\".dcm\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"SEED  = 42\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASSEED']  = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(SEED)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_columns = ['pe_present_on_image', 'negative_exam_for_pe', 'rv_lv_ratio_gte_1', \n                  'rv_lv_ratio_lt_1','leftsided_pe', 'chronic_pe','rightsided_pe', \n                  'acute_and_chronic_pe', 'central_pe', 'indeterminate']\n\nclasses = len(target_columns)\nmodel = models.resnet18(pretrained=False)\nin_features = model.fc.in_features\nmodel.fc = nn.Linear(in_features,classes)\n\nmodel_path = \"../input/rsna-super-cool-eda-and-pytorch-baseline-train/\"\n\nconfig={\n       \"learning_rate\":0.001,\n       \"train_batch_size\":32,\n        \"valid_batch_size\":32,\n        \"test_batch_size\":128,\n       \"epochs\":10,\n       \"nfolds\":8,\n       \"number_of_samples\":7000\n       }\n\nreader = vtk.vtkDICOMImageReader()\ndef get_img(path):\n    reader.SetFileName(path)\n    reader.Update()\n    _extent = reader.GetDataExtent()\n    ConstPixelDims = [_extent[1]-_extent[0]+1, _extent[3]-_extent[2]+1, _extent[5]-_extent[4]+1]\n\n    ConstPixelSpacing = reader.GetPixelSpacing()\n    imageData = reader.GetOutput()\n    pointData = imageData.GetPointData()\n    arrayData = pointData.GetArray(0)\n    ArrayDicom = numpy_support.vtk_to_numpy(arrayData)\n    ArrayDicom = ArrayDicom.reshape(ConstPixelDims, order='F')\n    ArrayDicom = cv2.resize(ArrayDicom,(512,512))\n    return ArrayDicom\n\n\n\ndef convert_to_rgb(array):\n    array = array.reshape((512, 512, 1))\n    return np.stack([array, array, array], axis=2).reshape((3,512, 512))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RsnaDataset(Dataset):\n    \n    def __init__(self,df,transforms=None):\n        super().__init__()\n        self.image_paths = df['ImagePath'].unique()\n        self.df = df\n        self.transforms = transforms\n    \n    def __getitem__(self,index):\n        \n        image_path = self.image_paths[index]\n        image = get_img(image_path)\n        image = convert_to_rgb(image)\n        \n        if self.transforms:\n            image = self.transforms(image=image)['image']\n            \n        image = torch.tensor(image,dtype=torch.float)        \n        \n        return image\n           \n    def __len__(self):\n        return self.image_paths.shape[0]  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def inference():\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    all_prediction = np.zeros((test_data.shape[0],len(target_columns)))\n    \n    for i in range(config[\"nfolds\"]):\n        model.load_state_dict(torch.load(f\"{model_path}model{i}.bin\"))\n        predictions = list()\n        model.to(device)\n        test_ds = RsnaDataset(test_data)\n        test_dl = DataLoader(test_ds,\n                        batch_size=config['test_batch_size'],\n                        shuffle=False)\n        \n        tqdm_loader = tqdm(test_dl)\n        with torch.no_grad():\n            for i, inputs in enumerate(tqdm_loader):\n                inputs = inputs.to(device, dtype=torch.float)\n                outputs= model(inputs) \n                predictions.extend(outputs.cpu().detach().numpy())\n\n        all_prediction += np.array(predictions)/config['nfolds']\n        \n    return all_prediction  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = inference()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}